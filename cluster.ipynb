{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55623352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'emoji.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13508/2832415313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mTweetdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emoji.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mTweetdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Tweets'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\capgemini\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             )\n\u001b[0;32m    708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emoji.txt'"
     ]
    }
   ],
   "source": [
    "# 18.500.000 Tweets importieren\n",
    "\n",
    "import pandas as pd\n",
    "Tweetdf = pd.read_csv('emoji.txt', error_bad_lines=False, lineterminator='\\n', delimiter='\\n')\n",
    "Tweetdf.columns = ['Tweets']\n",
    "\n",
    "print(Tweetdf.shape)\n",
    "Tweetdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228b07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emojis aus Tweets filtern\n",
    "\n",
    "from collections import Counter\n",
    "import emoji\n",
    "\n",
    "def extract_emojis(s):\n",
    "  return ''.join(set(c for c in s if c in emoji.UNICODE_EMOJI['en']))\n",
    "\n",
    "def count_emojis(s):\n",
    "  return len([i for i in s])\n",
    "\n",
    "Tweetdf['Emojis'] = Tweetdf['Tweets'].apply(extract_emojis)\n",
    "Tweetdf = Tweetdf.drop(['Tweets'], axis=1)\n",
    "\n",
    "myEmojis = Counter([emo for arr in Tweetdf['Emojis'].tolist() for emo in arr])\n",
    "\n",
    "CUT = len(Tweetdf) / 10000 \n",
    "\n",
    "def cut_rare_emojis(s):\n",
    "    myList = []\n",
    "    for i in s:\n",
    "        if myEmojis[i] > CUT:\n",
    "            myList.append(i)\n",
    "    return \"\".join(myList)\n",
    "        \n",
    "Tweetdf['Emojis'] = Tweetdf['Emojis'].apply(cut_rare_emojis)\n",
    "\n",
    "Tweetdf['nEmojis'] = Tweetdf['Emojis'].apply(count_emojis)\n",
    "Tweetdf = Tweetdf[Tweetdf['nEmojis'] >= 2].reset_index(drop=True)\n",
    "\n",
    "print(len(Tweetdf))\n",
    "Tweetdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e2f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuen Datensatz aus Emojis erstellen\n",
    "\n",
    "emojis = {}\n",
    "\n",
    "for indx, row in Tweetdf.iterrows():\n",
    "    for i in row['Emojis']:\n",
    "        if i not in emojis:\n",
    "            emojis[i] = [{j.strip():1 for j in row['Emojis']}, 1]\n",
    "\n",
    "        else:\n",
    "            emojis[i][1] += 1\n",
    "            for j in row['Emojis']:\n",
    "                eStrip = j.strip()\n",
    "                if eStrip in emojis[i][0]:\n",
    "                    emojis[i][0][eStrip] += 1\n",
    "\n",
    "                else:\n",
    "                    emojis[i][0][eStrip] = 1\n",
    "\n",
    "for key, val in emojis.items():\n",
    "    val[0].pop(key)\n",
    "\n",
    "EmojiData = {\n",
    "    'Emojis': [i for i in emojis.keys()],\n",
    "    'With': [i for i, j in emojis.values()],\n",
    "    'n': [j for i, j in emojis.values()]\n",
    "}\n",
    "\n",
    "Emojidf = pd.DataFrame(EmojiData)\n",
    "\n",
    "Emojidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dde64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Emojidf = pd.read_csv('emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering Class\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, data, startEmojis):\n",
    "        self.data = data\n",
    "        self.startEmojis = startEmojis\n",
    "        self.totalMeanDis = 1\n",
    "        self.minDis = [[], 1]\n",
    "        self.myClusters = self.startCluster()\n",
    "    \n",
    "    def startCluster(self):\n",
    "        myClusters = [{i:0} for i in self.startEmojis]\n",
    "        re, myClusters = self.algoCluster(myClusters, data=self.data, badLater=True)\n",
    "        print('badLater!')\n",
    "        totalMeanDis, myClusters = self.algoCluster(myClusters, data=re)\n",
    "        self.totalMeanDis = totalMeanDis\n",
    "        return myClusters\n",
    "    \n",
    "    def rearrangeCluster(self, n, badLater=False):\n",
    "        myClusters = deepcopy(self.myClusters)\n",
    "        re = []\n",
    "        for cluster in myClusters:\n",
    "            lastEmojis = list(cluster.keys())[n:]\n",
    "            for i in lastEmojis:\n",
    "                cluster.pop(i)\n",
    "                lastRow = Emojidf.loc[Emojidf.index[Emojidf['Emojis'] == i].values[0]]\n",
    "                re.append(lastRow)\n",
    "                for key in cluster.keys():\n",
    "                    cluster[key] -= self.getDistance(lastRow, key)\n",
    "        \n",
    "        random.shuffle(re)\n",
    "        if badLater:\n",
    "            re, myClusters = self.algoCluster(myClusters, data=re, badLater=True)\n",
    "            print('badLater!')\n",
    "        totalMeanDis, myClusters = self.algoCluster(myClusters, data=re)\n",
    "        return myClusters, totalMeanDis\n",
    "    \n",
    "    def getDistance(self, e1, e2):\n",
    "#         B = len(Tweetdf)\n",
    "        B = 6558070\n",
    "        N1 = e1['n']\n",
    "        N2 = Emojidf.loc[Emojidf.index[Emojidf['Emojis'] == e2].values[0], 'n']\n",
    "        T = eval(e1['With']).get(e2, 0)\n",
    "        Z = N1 * N2 / B\n",
    "        M = min(N1, N2)\n",
    "        D = (T - M) / (Z - M)\n",
    "        return D ** 2\n",
    "    \n",
    "    def algoCluster(self, myClusters, data, badLater=False):\n",
    "        reList = []\n",
    "        for row in data:\n",
    "            emoji = row['Emojis']\n",
    "            if emoji not in [e for cl in myClusters for e in cl.keys()]:\n",
    "                eCluster = {idx: [] for idx in range(len(myClusters))}\n",
    "                for idx, i in enumerate(myClusters):\n",
    "                    for j in i.keys():\n",
    "                        dis = self.getDistance(row, j)\n",
    "                        if dis < self.minDis[1]:\n",
    "                            self.minDis[1] = dis\n",
    "                            self.minDis[0] = [row, j]\n",
    "                        eCluster[idx].append(dis)\n",
    "\n",
    "                meanDis = [sum(eCluster[i]) / len(myClusters[i]) for i in range(len(myClusters))]\n",
    "                if badLater and min(meanDis) >= .8:\n",
    "                    reList.append(row)\n",
    "\n",
    "                else:\n",
    "                    eIdx = meanDis.index(min(meanDis))\n",
    "                    for idx, i in enumerate(myClusters[meanDis.index(min(meanDis))].keys()):\n",
    "                        myClusters[eIdx][i] += eCluster[eIdx][idx]\n",
    "                    myClusters[eIdx][emoji] = sum(eCluster[eIdx])\n",
    "                    print(f\"{emoji} -> {meanDis.index(min(meanDis)) + 1}\")\n",
    "\n",
    "        totalmeandis = 0\n",
    "        for idx, i in enumerate(myClusters):\n",
    "            j = dict(sorted(i.items(), key=lambda item: item[1]))\n",
    "            totalmeandis += sum(i.values()) / max(len(i.values()) - 1, 1) / max(len(i.values()), 1)\n",
    "            myClusters[idx] = j\n",
    "        totalmeandis /= len(myClusters)\n",
    "            \n",
    "        if badLater:\n",
    "            return reList, myClusters\n",
    "\n",
    "        return totalmeandis, myClusters\n",
    "    \n",
    "    def summarizeCluster(self):\n",
    "        for idx, i in enumerate(self.myClusters):\n",
    "            print(f'\\n{idx+1}')\n",
    "            print(''.join(i.keys()))\n",
    "        print(f'\\n{self.totalMeanDis}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aabed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data and create cluster entity\n",
    "\n",
    "import random\n",
    "\n",
    "shuffleData = list(Emojidf.iterrows())\n",
    "random.shuffle(shuffleData)\n",
    "shuffleData = [row for idx, row in shuffleData]\n",
    "\n",
    "cluster = Cluster(shuffleData, ['ü§î', '‚ôÄ', 'üå∏', 'üêæ', 'üç∞', 'üéß', 'üèÜ', 'üëâ', 'üö®', 'üé•'])\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c3d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize created clusters and rearrange poor connected emojis\n",
    "\n",
    "print(cluster.totalMeanDis)\n",
    "newCluster, new = cluster.rearrangeCluster(20, badLater=True)\n",
    "cluster.myCluster = newCluster\n",
    "newCluster, new = cluster.rearrangeCluster(-15)\n",
    "while new < cluster.totalMeanDis:\n",
    "    cluster.myCluster, cluster.totalMeanDis = newCluster, new\n",
    "    newCluster, new = cluster.rearrangeCluster(-15)\n",
    "print(cluster.summarizeCluster())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
